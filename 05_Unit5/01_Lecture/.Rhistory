demo()
glm()
GLM.VR
glm.vr
library("rstudio", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
install.packages(c("manipulate", "mgcv"))
clear
close
exit
sd(c(5,8,12))
which.min(c(4,1,6))
Sys.setlocale("LC_ALL", "C")
exit()
quit
1 + 26+40+34+23+26+20+30+15
1 + 26+40+34+23+26+20+30+15 / 60
(1 + 26+40+34+23+26+20+30+15) / 60
(1+6+17+10+15+6+7+5) / 60
(1+8+7+8+4)
1+19+29+22+29+27+18+30+38
(1+19+29+22+29+27+18+30+38)/60
q()
sd(c(5,8,12))
which.min(c(4,1,6))
60 * (15/24)^(1.3-1)
1.71(515-490)
1.71*(515-490)
101*1000*30/ (1200 * 8.314)
(101*1000*30/ (1200 * 8.314)) - 273
10 * (10/7)^2
4.18 * 65
16*8.314*373.15
30 * (.08 *22.6)^1.3
1000*5 * 3.14 * 1.5^2
1000*5 * 3.14 * (1.5)^2
5.34^2 * 936 / 30
333 * (24/15)^0.3
333 * (15/24)^0.3
(101*1000*15*20*5)/(8.314*298.15)
(28.966*101*15*20*5)/(8.314*298.15)
15 * (7/8)^2
quit(0)
exit(0)
exit()
quit("yes")
a = c(100,90,70,65,85)
mean(a)
a = a -mean(a)
a = a^2
sum(a)
a = c(100,90,70,65,85)
sd(a)
a = c(45,80,95,55,30)
a = a - mean(a)
a = a ^2
sum(a)
a = c(45,80,95,55,30)
b = c(40,80,140,60,20)
b = b - a
b = b ^ 2
sum(b)
1 - (2175/2770)
day = c(1,25,46,76,140)
act = c(5,15,22,32,77)
line1 = 0.6 * day
line 2 = 0.5 * day
line2 = 0.5 * day
SST = sum((act - mean(act))^2)
SSE1 = sum((act - line1)^2)
SSE2 = sum((act - line2)^2)
1 - SSE1/SST
1 - SSE2/SST
install.packages("caret")
library(caret)
q()
setwd("~/Documents/01_Courses/13_Analytics_edge_MIT/05_Unit5/01_Lecture")
install.packages("tm")
install.packages("SnowballC")
setwd("~/Documents/01_Courses/13_Analytics_edge_MIT/05_Unit5/01_Lecture")
tweets = read.csv("tweets.csv", stringsAsFactors = F)
str(tweets)
tweets$Negative = as.factor(tweets$Avg <= -1)
table(tweets$Negative)
library(tm)
library(SnowballC)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus
corpus[[1]]
corpus = tm_map(corpus, PlainTextDocument)
corpus[[1]]
corpus
summary(corpus)
corpus[1]
corpus[[1,]]
corpus[[1]]
corpus[[1]]$content
library(tm)
library(SnowballC)
# Create corpus
corpus = Corpus(VectorSource(tweets$Tweet))
# Look at corpus
corpus
corpus[[1]]
# Convert to lower-case
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = Corpus(VectorSource(tweets$Tweet))
# Look at corpus
corpus
corpus[[1]]
corpus = tm_map(corpus, PlainTextDocument)
corpus[[1]]
?tm_map
corpus[[1]]
# Convert to lower-case
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
stopwords("english")[1:10]
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus[[1]]
corpus = tm_map(corpus, stemDocument)
corpus[[1]]
corpus = tm_map(corpus, stemDocument)
corpus[[1]]
tweets = read.csv("tweets.csv", stringsAsFactors=FALSE)
str(tweets)
# Create dependent variable
tweets$Negative = as.factor(tweets$Avg <= -1)
table(tweets$Negative)
# Install new packages
install.packages("tm")
library(tm)
library(SnowballC)
# Create corpus
corpus = Corpus(VectorSource(tweets$Tweet))
# Look at corpus
corpus
corpus = tm_map(corpus, PlainTextDocument)
corpus[[1]]
# Convert to lower-case
corpus = tm_map(corpus, tolower)
corpus[[1]]
# IMPORTANT NOTE: If you are using the latest version of the tm package, you will need to run the following line before continuing (it converts corpus to a Plain Text Document). This is a recent change having to do with the tolower function that occurred after this video was recorded.
corpus = tm_map(corpus, PlainTextDocument)
# Remove punctuation
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
# Look at stop words
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]
corpus = Corpus(VectorSource(tweets$Tweet))
# Look at corpus
corpus
corpus = tm_map(corpus, PlainTextDocument)
corpus[[1]]$content
# Convert to lower-case
corpus = tm_map(corpus, tolower)
corpus[[1]]$content
corpus[[1]]
# IMPORTANT NOTE: If you are using the latest version of the tm package, you will need to run the following line before continuing (it converts corpus to a Plain Text Document). This is a recent change having to do with the tolower function that occurred after this video was recorded.
corpus = tm_map(corpus, PlainTextDocument)
# Remove punctuation
corpus = tm_map(corpus, removePunctuation)
corpus[[1]]$content
# Look at stop words
stopwords("english")[1:10]
# Remove stopwords and apple
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
corpus[[1]]$content
# Stem document
corpus = tm_map(corpus, stemDocument)
corpus[[1]]
corpus[[1]]$content
frequncies = DocumentTermMatrix(corpus)
frequncies
inspect(frequncies[1000:1005, 505:515])
findFreqTerms(frequncies, lowfreq = 20)
sparse = removeSparseTerms(frequncies, 0.995)
sparse
tweetsSparse = as.data.frame.(as.matrix(sparse))
tweetsSparse = as.data.frame(as.matrix(sparse))
colnames(tweetsSparse = make.names(colnames(tweetsSparse)))
colnames(tweetsSparse) = make.names(colnames(tweetsSparse))
tweetsSparse$Negative = tweets$Negative
library(caTools)
set seed (123)spl = sample.split()
set seed (123)
set.seed (123)
split = sample.split(tweetsSparse$Negative , SplitRatio = 0.7)
trainSparse = subset(tweetsSparse, split = T)
testSparse = subset(tweetsSparse, split == F)
trainSparse = subset(tweetsSparse, split == T)
findFreqTerms(frequncies, lowfreq = 100)
library(rpart)
library(rpart.plot)
twetcart = rpart(Negative ~ ., data = trainSparse, methos = "class")
twetcart = rpart(Negative ~ ., data = trainSparse, method = "class")
prp(twetcart)
tweetcart = rpart(Negative ~ ., data = trainSparse, method = "class")
prp(tweetcart)
rm(twetcart)
predictCART = predict(tweetcart, newdata = testSparse, type = "class")
table(testSparse$Negative, predictCART)
table(testSparse$Negative)
300/355
library(randomForest)
set.seed(123)
tweetRF= randomForest(Negative ~ ., data= trainSparse)
predictRF= predict(tweetRF, newdata = testSparse)
table(testSparse$Negative, predictRF)
(292 + 21) / sum(table(testSparse$Negative, predictRF))
tweetLog = glm(Negative ~ . , data = trainSparse, family ="binomial")
predictLog = predict(tweetLog, newdata = testSparse)
table(testSparse$Negative, predictLog > 0.5)
(253+32) / 355
predictLog = predict(tweetLog, newdata = testSparse , type = "response")
table(testSparse$Negative, predictLog > 0.5)
rm(list = ls())
q()
